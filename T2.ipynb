{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T2: Neural IBM1 (with additional French context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xb but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xb but this version of numpy is 0xa"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-cd7db09f153e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvocabulary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/rezka/anaconda2/envs/py35/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pylab_helpers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rezka/anaconda2/envs/py35/lib/python3.5/site-packages/matplotlib/colorbar.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmartist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rezka/anaconda2/envs/py35/lib/python3.5/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmplDeprecation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m from .transforms import (Bbox, IdentityTransform, TransformedBbox,\n\u001b[0m\u001b[1;32m     16\u001b[0m                          TransformedPath, Transform)\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rezka/anaconda2/envs/py35/lib/python3.5/site-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m from matplotlib._path import (affine_transform, count_bboxes_overlapping_bbox,\n\u001b[0m\u001b[1;32m     40\u001b[0m     update_path_extents)\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "# first run a few imports:\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "from utils import smart_reader, bitext_reader\n",
    "from vocabulary import OrderedCounter, Vocabulary \n",
    "from utils import iterate_minibatches, prepare_data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the paths to our training and validation data, English side\n",
    "train_e_path = 'data/training/hansards.36.2.e.gz'\n",
    "train_f_path = 'data/training/hansards.36.2.f.gz'\n",
    "dev_e_path = 'data/validation/dev.e.gz'\n",
    "dev_f_path = 'data/validation/dev.f.gz'\n",
    "dev_wa = 'data/validation/dev.wa.nonullalign'\n",
    "test_e_path = 'data/test/test.e.gz'\n",
    "test_f_path = 'data/test/test.f.gz'\n",
    "test_wa = 'data/test/test.wa.nonullalign'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using only 1000 words will result in many UNKs, but\n",
    "# it will make training a lot faster. \n",
    "# If you have a fast computer, a GPU, or a lot of time,\n",
    "# try with 10000 instead.\n",
    "max_tokens=1000\n",
    "\n",
    "corpus_e = smart_reader(train_e_path)    \n",
    "vocabulary_e = Vocabulary(corpus=corpus_e, max_tokens=max_tokens)\n",
    "pickle.dump(vocabulary_e, open(\"vocabulary_e.pkl\", mode=\"wb\"))\n",
    "\n",
    "corpus_f = smart_reader(train_f_path)    \n",
    "vocabulary_f = Vocabulary(corpus=corpus_f, max_tokens=max_tokens)\n",
    "pickle.dump(vocabulary_f, open(\"vocabulary_f.pkl\", mode=\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neuralibm1 import NeuralIBM1Model\n",
    "from neuralibm1trainer import NeuralIBM1Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with B=16 max_length=3 lr=0.001 lr_decay=0.0\n",
      "Initializing variables..\n",
      "Training started..\n",
      "Shuffling training data\n",
      "Iter   100 loss 5.202702 accuracy 0.47 lr 0.001000\n",
      "Iter   200 loss 4.486246 accuracy 0.51 lr 0.001000\n",
      "Iter   300 loss 3.400743 accuracy 0.67 lr 0.001000\n",
      "Iter   400 loss 3.942848 accuracy 0.59 lr 0.001000\n",
      "Iter   500 loss 1.984764 accuracy 0.65 lr 0.001000\n",
      "Iter   600 loss 1.456665 accuracy 0.75 lr 0.001000\n",
      "Iter   700 loss 1.521330 accuracy 0.67 lr 0.001000\n",
      "Iter   800 loss 2.636425 accuracy 0.60 lr 0.001000\n",
      "Iter   900 loss 2.757921 accuracy 0.64 lr 0.001000\n",
      "Iter  1000 loss 2.243395 accuracy 0.58 lr 0.001000\n",
      "Iter  1100 loss 2.500443 accuracy 0.56 lr 0.001000\n",
      "Iter  1200 loss 3.642543 accuracy 0.42 lr 0.001000\n",
      "Iter  1300 loss 1.270955 accuracy 0.71 lr 0.001000\n",
      "Iter  1400 loss 2.132542 accuracy 0.53 lr 0.001000\n",
      "Epoch 1 loss 3.000606 accuracy 0.57 val_aer 0.92 val_acc 0.19\n",
      "Computing training-set likelihood\n",
      "Computing dev-set likelihood\n",
      "Model saved in file: model.ckpt\n",
      "Shuffling training data\n",
      "Iter   100 loss 1.935100 accuracy 0.54 lr 0.001000\n",
      "Iter   200 loss 2.214538 accuracy 0.58 lr 0.001000\n",
      "Iter   300 loss 3.410626 accuracy 0.57 lr 0.001000\n",
      "Iter   400 loss 1.290445 accuracy 0.71 lr 0.001000\n",
      "Iter   500 loss 1.528390 accuracy 0.69 lr 0.001000\n",
      "Iter   600 loss 1.828117 accuracy 0.63 lr 0.001000\n",
      "Iter   700 loss 1.861131 accuracy 0.59 lr 0.001000\n",
      "Iter   800 loss 1.943371 accuracy 0.64 lr 0.001000\n",
      "Iter   900 loss 1.941771 accuracy 0.61 lr 0.001000\n",
      "Iter  1000 loss 1.373476 accuracy 0.71 lr 0.001000\n",
      "Iter  1100 loss 1.709401 accuracy 0.60 lr 0.001000\n",
      "Iter  1200 loss 1.748399 accuracy 0.61 lr 0.001000\n",
      "Iter  1300 loss 2.757200 accuracy 0.50 lr 0.001000\n",
      "Iter  1400 loss 1.961179 accuracy 0.55 lr 0.001000\n",
      "Epoch 2 loss 1.879752 accuracy 0.61 val_aer 0.93 val_acc 0.19\n",
      "Computing training-set likelihood\n",
      "Computing dev-set likelihood\n",
      "Model saved in file: model.ckpt\n",
      "Shuffling training data\n",
      "Iter   100 loss 1.477742 accuracy 0.69 lr 0.001000\n",
      "Iter   200 loss 1.309891 accuracy 0.70 lr 0.001000\n",
      "Iter   300 loss 2.185716 accuracy 0.54 lr 0.001000\n",
      "Iter   400 loss 2.402937 accuracy 0.55 lr 0.001000\n",
      "Iter   500 loss 1.110985 accuracy 0.75 lr 0.001000\n",
      "Iter   600 loss 1.687388 accuracy 0.62 lr 0.001000\n",
      "Iter   700 loss 1.093440 accuracy 0.76 lr 0.001000\n",
      "Iter   800 loss 1.756940 accuracy 0.59 lr 0.001000\n",
      "Iter   900 loss 1.327901 accuracy 0.69 lr 0.001000\n",
      "Iter  1000 loss 1.630532 accuracy 0.65 lr 0.001000\n",
      "Iter  1100 loss 2.090215 accuracy 0.55 lr 0.001000\n",
      "Iter  1200 loss 1.699890 accuracy 0.60 lr 0.001000\n",
      "Iter  1300 loss 2.267998 accuracy 0.46 lr 0.001000\n",
      "Iter  1400 loss 1.646211 accuracy 0.59 lr 0.001000\n",
      "Epoch 3 loss 1.794803 accuracy 0.61 val_aer 0.92 val_acc 0.19\n",
      "Computing training-set likelihood\n",
      "Computing dev-set likelihood\n",
      "Model saved in file: model.ckpt\n",
      "Shuffling training data\n",
      "Iter   100 loss 1.763519 accuracy 0.59 lr 0.001000\n",
      "Iter   200 loss 2.420856 accuracy 0.55 lr 0.001000\n",
      "Iter   300 loss 1.543128 accuracy 0.68 lr 0.001000\n",
      "Iter   400 loss 1.607620 accuracy 0.65 lr 0.001000\n",
      "Iter   500 loss 1.332456 accuracy 0.67 lr 0.001000\n",
      "Iter   600 loss 1.465945 accuracy 0.66 lr 0.001000\n",
      "Iter   700 loss 1.531387 accuracy 0.66 lr 0.001000\n",
      "Iter   800 loss 1.640249 accuracy 0.64 lr 0.001000\n",
      "Iter   900 loss 1.778772 accuracy 0.58 lr 0.001000\n",
      "Iter  1000 loss 2.248056 accuracy 0.54 lr 0.001000\n",
      "Iter  1100 loss 2.885820 accuracy 0.43 lr 0.001000\n",
      "Iter  1200 loss 1.785116 accuracy 0.62 lr 0.001000\n",
      "Iter  1300 loss 2.460109 accuracy 0.50 lr 0.001000\n",
      "Iter  1400 loss 1.601605 accuracy 0.70 lr 0.001000\n",
      "Epoch 4 loss 1.767960 accuracy 0.61 val_aer 0.92 val_acc 0.19\n",
      "Computing training-set likelihood\n",
      "Computing dev-set likelihood\n",
      "Model saved in file: model.ckpt\n",
      "Shuffling training data\n",
      "Iter   100 loss 1.571901 accuracy 0.67 lr 0.001000\n",
      "Iter   200 loss 1.697388 accuracy 0.58 lr 0.001000\n",
      "Iter   300 loss 1.747190 accuracy 0.63 lr 0.001000\n",
      "Iter   400 loss 1.500937 accuracy 0.62 lr 0.001000\n",
      "Iter   500 loss 1.732344 accuracy 0.53 lr 0.001000\n",
      "Iter   600 loss 1.662098 accuracy 0.60 lr 0.001000\n",
      "Iter   700 loss 1.731992 accuracy 0.50 lr 0.001000\n",
      "Iter   800 loss 1.875510 accuracy 0.59 lr 0.001000\n",
      "Iter   900 loss 1.861370 accuracy 0.55 lr 0.001000\n",
      "Iter  1000 loss 1.918442 accuracy 0.54 lr 0.001000\n",
      "Iter  1100 loss 1.973174 accuracy 0.56 lr 0.001000\n",
      "Iter  1200 loss 2.089715 accuracy 0.60 lr 0.001000\n",
      "Iter  1300 loss 2.075514 accuracy 0.56 lr 0.001000\n",
      "Iter  1400 loss 1.276870 accuracy 0.74 lr 0.001000\n",
      "Epoch 5 loss 1.755568 accuracy 0.61 val_aer 0.92 val_acc 0.19\n",
      "Computing training-set likelihood\n",
      "Computing dev-set likelihood\n",
      "Model saved in file: model.ckpt\n",
      "Shuffling training data\n",
      "Iter   100 loss 1.315245 accuracy 0.69 lr 0.001000\n",
      "Iter   200 loss 1.630572 accuracy 0.65 lr 0.001000\n",
      "Iter   300 loss 1.958528 accuracy 0.61 lr 0.001000\n",
      "Iter   400 loss 2.616179 accuracy 0.50 lr 0.001000\n",
      "Iter   500 loss 2.376743 accuracy 0.51 lr 0.001000\n",
      "Iter   600 loss 1.701851 accuracy 0.61 lr 0.001000\n",
      "Iter   700 loss 1.499439 accuracy 0.61 lr 0.001000\n",
      "Iter   800 loss 1.896992 accuracy 0.63 lr 0.001000\n",
      "Iter   900 loss 1.750803 accuracy 0.57 lr 0.001000\n",
      "Iter  1000 loss 1.565158 accuracy 0.65 lr 0.001000\n",
      "Iter  1100 loss 1.897678 accuracy 0.59 lr 0.001000\n",
      "Iter  1200 loss 1.639646 accuracy 0.66 lr 0.001000\n",
      "Iter  1300 loss 1.708784 accuracy 0.62 lr 0.001000\n",
      "Iter  1400 loss 2.269729 accuracy 0.58 lr 0.001000\n",
      "Epoch 6 loss 1.749531 accuracy 0.61 val_aer 0.92 val_acc 0.19\n",
      "Computing training-set likelihood\n",
      "Computing dev-set likelihood\n",
      "Model saved in file: model.ckpt\n",
      "Shuffling training data\n",
      "Iter   100 loss 2.196653 accuracy 0.56 lr 0.001000\n",
      "Iter   200 loss 1.287501 accuracy 0.67 lr 0.001000\n",
      "Iter   300 loss 1.303164 accuracy 0.69 lr 0.001000\n",
      "Iter   400 loss 1.532844 accuracy 0.67 lr 0.001000\n",
      "Iter   500 loss 1.746188 accuracy 0.62 lr 0.001000\n",
      "Iter   600 loss 1.634478 accuracy 0.62 lr 0.001000\n",
      "Iter   700 loss 1.633932 accuracy 0.67 lr 0.001000\n",
      "Iter   800 loss 1.838611 accuracy 0.55 lr 0.001000\n",
      "Iter   900 loss 1.609675 accuracy 0.67 lr 0.001000\n",
      "Iter  1000 loss 2.441458 accuracy 0.57 lr 0.001000\n",
      "Iter  1100 loss 1.668973 accuracy 0.63 lr 0.001000\n",
      "Iter  1200 loss 1.921747 accuracy 0.59 lr 0.001000\n",
      "Iter  1300 loss 2.127032 accuracy 0.53 lr 0.001000\n",
      "Iter  1400 loss 1.678817 accuracy 0.67 lr 0.001000\n",
      "Epoch 7 loss 1.745555 accuracy 0.61 val_aer 0.93 val_acc 0.19\n",
      "Computing training-set likelihood\n",
      "Computing dev-set likelihood\n",
      "Model saved in file: model.ckpt\n",
      "Shuffling training data\n",
      "Iter   100 loss 2.200706 accuracy 0.50 lr 0.001000\n",
      "Iter   200 loss 1.711846 accuracy 0.58 lr 0.001000\n",
      "Iter   300 loss 1.028531 accuracy 0.80 lr 0.001000\n",
      "Iter   400 loss 1.567322 accuracy 0.67 lr 0.001000\n",
      "Iter   500 loss 1.265717 accuracy 0.70 lr 0.001000\n",
      "Iter   600 loss 1.688627 accuracy 0.65 lr 0.001000\n",
      "Iter   700 loss 1.561924 accuracy 0.67 lr 0.001000\n",
      "Iter   800 loss 1.145648 accuracy 0.72 lr 0.001000\n",
      "Iter   900 loss 2.275695 accuracy 0.53 lr 0.001000\n",
      "Iter  1000 loss 1.752257 accuracy 0.62 lr 0.001000\n",
      "Iter  1100 loss 2.411668 accuracy 0.46 lr 0.001000\n",
      "Iter  1200 loss 1.727700 accuracy 0.61 lr 0.001000\n",
      "Iter  1300 loss 1.533015 accuracy 0.65 lr 0.001000\n",
      "Iter  1400 loss 2.084981 accuracy 0.55 lr 0.001000\n",
      "Epoch 8 loss 1.744705 accuracy 0.61 val_aer 0.93 val_acc 0.19\n",
      "Computing training-set likelihood\n",
      "Computing dev-set likelihood\n",
      "Model saved in file: model.ckpt\n",
      "Shuffling training data\n",
      "Iter   100 loss 1.651990 accuracy 0.61 lr 0.001000\n",
      "Iter   200 loss 1.409286 accuracy 0.69 lr 0.001000\n",
      "Iter   300 loss 1.596489 accuracy 0.64 lr 0.001000\n",
      "Iter   400 loss 1.420896 accuracy 0.71 lr 0.001000\n",
      "Iter   500 loss 1.393485 accuracy 0.68 lr 0.001000\n",
      "Iter   600 loss 1.133400 accuracy 0.75 lr 0.001000\n",
      "Iter   700 loss 1.818644 accuracy 0.63 lr 0.001000\n",
      "Iter   800 loss 1.782123 accuracy 0.61 lr 0.001000\n",
      "Iter   900 loss 2.014609 accuracy 0.60 lr 0.001000\n",
      "Iter  1000 loss 1.751131 accuracy 0.60 lr 0.001000\n",
      "Iter  1100 loss 2.020670 accuracy 0.57 lr 0.001000\n",
      "Iter  1200 loss 1.592150 accuracy 0.62 lr 0.001000\n",
      "Iter  1300 loss 1.891079 accuracy 0.62 lr 0.001000\n",
      "Iter  1400 loss 1.785778 accuracy 0.57 lr 0.001000\n",
      "Epoch 9 loss 1.741800 accuracy 0.61 val_aer 0.92 val_acc 0.19\n",
      "Computing training-set likelihood\n",
      "Computing dev-set likelihood\n",
      "Model saved in file: model.ckpt\n",
      "Shuffling training data\n",
      "Iter   100 loss 2.314706 accuracy 0.53 lr 0.001000\n",
      "Iter   200 loss 1.454924 accuracy 0.71 lr 0.001000\n",
      "Iter   300 loss 1.359721 accuracy 0.69 lr 0.001000\n",
      "Iter   400 loss 1.371310 accuracy 0.69 lr 0.001000\n",
      "Iter   500 loss 1.931033 accuracy 0.54 lr 0.001000\n",
      "Iter   600 loss 1.250962 accuracy 0.69 lr 0.001000\n",
      "Iter   700 loss 1.710952 accuracy 0.56 lr 0.001000\n",
      "Iter   800 loss 1.732684 accuracy 0.59 lr 0.001000\n",
      "Iter   900 loss 1.802230 accuracy 0.55 lr 0.001000\n",
      "Iter  1000 loss 1.896956 accuracy 0.56 lr 0.001000\n",
      "Iter  1100 loss 2.394307 accuracy 0.50 lr 0.001000\n",
      "Iter  1200 loss 1.898163 accuracy 0.58 lr 0.001000\n",
      "Iter  1300 loss 1.645987 accuracy 0.63 lr 0.001000\n",
      "Iter  1400 loss 1.863981 accuracy 0.57 lr 0.001000\n",
      "Epoch 10 loss 1.742226 accuracy 0.61 val_aer 0.92 val_acc 0.19\n",
      "Computing training-set likelihood\n",
      "Computing dev-set likelihood\n",
      "Model saved in file: model.ckpt\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # some hyper-parameters\n",
    "    # tweak them as you wish\n",
    "    batch_size=16  # on CPU, use something much smaller e.g. 1-16\n",
    "    max_length=30\n",
    "    lr = 0.001\n",
    "    lr_decay = 0.0  # set to 0.0 when using Adam optimizer (default)\n",
    "    emb_dim = 64\n",
    "    mlp_dim = 128\n",
    "\n",
    "    # our model\n",
    "    # change context to : \"gate\", \"concat\", or \"col_discrete\". \"col_discrete is for T3\"\n",
    "    model = NeuralIBM1Model(\n",
    "        x_vocabulary=vocabulary_e, y_vocabulary=vocabulary_f, \n",
    "        batch_size=batch_size, emb_dim=emb_dim, mlp_dim=mlp_dim, session=sess, context=\"concat\")\n",
    "\n",
    "    # our trainer\n",
    "    trainer = NeuralIBM1Trainer(\n",
    "        model, train_e_path, train_f_path, \n",
    "        dev_e_path, dev_f_path, dev_wa,\n",
    "        test_e_path, test_f_path, test_wa,\n",
    "        num_epochs=10, batch_size=batch_size, \n",
    "        max_length=max_length, lr=lr, lr_decay=lr_decay, session=sess)\n",
    "\n",
    "    # now first TF needs to initialize all the variables\n",
    "    print(\"Initializing variables..\")\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # now we can start training!\n",
    "    print(\"Training started..\")\n",
    "    results = trainer.train()\n",
    "    dev_AERs, test_AERs, train_likelihoods, dev_likelihoods = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/rezka/anaconda2/envs/py35/lib/python3.5/site-packages/numpy']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print (np.__path__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xb but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xb but this version of numpy is 0xa"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-dbac6b694f2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhandles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_AERs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_AERs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dev-set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rezka/anaconda2/envs/py35/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pylab_helpers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rezka/anaconda2/envs/py35/lib/python3.5/site-packages/matplotlib/colorbar.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmartist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rezka/anaconda2/envs/py35/lib/python3.5/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmplDeprecation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m from .transforms import (Bbox, IdentityTransform, TransformedBbox,\n\u001b[0m\u001b[1;32m     16\u001b[0m                          TransformedPath, Transform)\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rezka/anaconda2/envs/py35/lib/python3.5/site-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m from matplotlib._path import (affine_transform, count_bboxes_overlapping_bbox,\n\u001b[0m\u001b[1;32m     40\u001b[0m     update_path_extents)\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "handles = []\n",
    "ax1 = plt.plot(range(1, len(dev_AERs)+1), dev_AERs, label='dev-set')\n",
    "handles.extend(ax1)\n",
    "ax2 = plt.plot(range(1, len(test_AERs)+1), test_AERs, label='test-set')\n",
    "handles.extend(ax2)\n",
    "plt.legend(handles=handles)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('AER')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "handles = []\n",
    "ax1 = plt.plot(range(1, len(train_likelihoods)+1), train_likelihoods, label='training-set')\n",
    "handles.extend(ax1)\n",
    "plt.legend(handles=handles)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('log-likelihood')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "handles = []\n",
    "ax1 = plt.plot(range(1, len(dev_likelihoods)+1), dev_likelihoods, label='dev-set')\n",
    "handles.extend(ax1)\n",
    "plt.legend(handles=handles)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('log-likelihood')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # some hyper-parameters\n",
    "    # tweak them as you wish\n",
    "    batch_size=16  # on CPU, use something much smaller e.g. 1-16\n",
    "    max_length=30\n",
    "    lr = 0.001\n",
    "    lr_decay = 0.0  # set to 0.0 when using Adam optimizer (default)\n",
    "    emb_dim = 64\n",
    "    mlp_dim = 128\n",
    "\n",
    "    # our model\n",
    "    # change context to : \"gate\", \"concat\", or \"col_discrete\". \"col_discrete is for T3\"\n",
    "    model = NeuralIBM1Model(\n",
    "        x_vocabulary=vocabulary_e, y_vocabulary=vocabulary_f, \n",
    "        batch_size=batch_size, emb_dim=emb_dim, mlp_dim=mlp_dim, session=sess, context=\"gate\")\n",
    "\n",
    "    # our trainer\n",
    "    trainer = NeuralIBM1Trainer(\n",
    "        model, train_e_path, train_f_path, \n",
    "        dev_e_path, dev_f_path, dev_wa,\n",
    "        test_e_path, test_f_path, test_wa,\n",
    "        num_epochs=10, batch_size=batch_size, \n",
    "        max_length=max_length, lr=lr, lr_decay=lr_decay, session=sess)\n",
    "\n",
    "    # now first TF needs to initialize all the variables\n",
    "    print(\"Initializing variables..\")\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # now we can start training!\n",
    "    print(\"Training started..\")\n",
    "    results = trainer.train()\n",
    "    dev_AERs, test_AERs, train_likelihoods, dev_likelihoods = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "handles = []\n",
    "ax1 = plt.plot(range(1, len(dev_AERs)+1), dev_AERs, label='dev-set')\n",
    "handles.extend(ax1)\n",
    "ax2 = plt.plot(range(1, len(test_AERs)+1), test_AERs, label='test-set')\n",
    "handles.extend(ax2)\n",
    "plt.legend(handles=handles)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('AER')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "handles = []\n",
    "ax1 = plt.plot(range(1, len(train_likelihoods)+1), train_likelihoods, label='training-set')\n",
    "handles.extend(ax1)\n",
    "plt.legend(handles=handles)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('log-likelihood')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "handles = []\n",
    "ax1 = plt.plot(range(1, len(dev_likelihoods)+1), dev_likelihoods, label='dev-set')\n",
    "handles.extend(ax1)\n",
    "plt.legend(handles=handles)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('log-likelihood')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
